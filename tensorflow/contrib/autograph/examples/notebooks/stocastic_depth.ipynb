{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stocastic Network Depth with Autograph.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lXy_TOKESG1j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stocastic Network Depth with Autograph\n",
        "\n",
        "\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\"><td>\n",
        "<a target=\"_blank\"  href=\"https://colab.research.google.com/github/tensorflow/tensorflow/tree/master/tensorflow/contrib/autograph/examples/notebooks/stocastic_depth.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
        "</td><td>\n",
        "<a target=\"_blank\"  href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/autograph/examples/notebooks/stocastic_depth.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
      ]
    },
    {
      "metadata": {
        "id": "6ouSvrPgA1jL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "An AutoGraph implementation of: https://arxiv.org/abs/1603.09382 as a keras model."
      ]
    },
    {
      "metadata": {
        "id": "fRoex23PUlhV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CGvf3Y_hruPP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.contrib import autograph\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "tf.VERSION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aIpRDW1vBawK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "But to debug the model it might be convienient to shut off AutoGraph enable eager execution. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "dD9FQKKcmcnx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if tf.executing_eagerly():\n",
        "  def convert():\n",
        "    def decorate(func):\n",
        "      return func\n",
        "    return decorate\n",
        "else:\n",
        "  convert = autograph.convert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NBp_Sy81Cgd4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The main idea is the `StocasticNetworkDepth` model. It's like a `tf.keras.Sequential` model except that each layer is run or skipped with a certain probability.\n",
        "\n",
        "This is easily expressed in python, and converted for graph execution with `tf.contrib.autograph`:"
      ]
    },
    {
      "metadata": {
        "id": "PZ9Y1D6ptu-0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "class StocasticNetworkDepth(tf.keras.Sequential):\n",
        "  def __init__(self, pfirst=1.0, plast=0.5, **kwargs):\n",
        "    self.pfirst = pfirst\n",
        "    self.plast = plast\n",
        "         \n",
        "    super(StocasticNetworkDepth, self).__init__(**kwargs)\n",
        "\n",
        "  @convert()\n",
        "  def call(self, inputs):\n",
        "    training = K.learning_phase()\n",
        "    \n",
        "    if not training:\n",
        "      return super(StocasticNetworkDepth, self).call(inputs)\n",
        "    \n",
        "    depth = len(self.layers)\n",
        "    plims = tf.lin_space(self.pfirst, self.plast, depth)\n",
        "    \n",
        "    p = tf.random_uniform((depth,), dtype=tf.float32)\n",
        "    \n",
        "    skips = p>=plims\n",
        "    x = inputs\n",
        "    for i in range(depth):\n",
        "      x = self.layers[i](x, skip=skips[i])\n",
        "        \n",
        "    return x\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g0xh0sBvEyqq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Image sizes or sequence lengths _can_ change, as long as the rest of the output head is insensitive to the image (use global pooling, not a \"fully connected\" layer).\n",
        "\n",
        "The layers of this model are residual-blocks containing two colvolutions, some supporting batch norm layers, and a bypass connection:  "
      ]
    },
    {
      "metadata": {
        "id": "g3WXsuPExj3w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class PadChannels(layers.Layer):\n",
        "  def __init__(self, channels):\n",
        "    super(PadChannels, self).__init__()\n",
        "    self.channels = channels\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    in_shape = tf.shape(inputs)\n",
        "    missing_channels = tf.convert_to_tensor(self.channels-in_shape[-1])\n",
        "    z_shape = tf.concat([in_shape[:-1], missing_channels[tf.newaxis]], axis=0)\n",
        "    zeros = tf.zeros(shape = z_shape, dtype=inputs.dtype)\n",
        "    return tf.concat([inputs, zeros], axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yejaATA2NGpX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NoOp(layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cc5GiYF83UAq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SkippableResBlock(tf.keras.Model):   \n",
        "  def __init__(self, channels, downsample=False):\n",
        "    super(SkippableResBlock, self).__init__()\n",
        "    \n",
        "    self.downsample=downsample\n",
        "    \n",
        "    if self.downsample:\n",
        "      strides=(2,2)\n",
        "      self.bypass1 = layers.AveragePooling2D(strides, strides)\n",
        "      self.bypass2 = PadChannels(channels)\n",
        "    else:\n",
        "      strides=(1,1)\n",
        "      self.bypass1 = NoOp()\n",
        "      self.bypass2 = NoOp()\n",
        "      \n",
        "    self.conv1 = layers.Conv2D(channels, (3,3), padding='same', strides=strides,\n",
        "                               kernel_initializer='he_normal', use_bias=False) \n",
        "    self.bn1 = layers.BatchNormalization()\n",
        "    self.relu1 = layers.Activation('relu')\n",
        "    self.conv2 = layers.Conv2D(channels, (3,3), padding='same', \n",
        "                               kernel_initializer='he_normal', use_bias=False) \n",
        "    self.bn2 = layers.BatchNormalization() \n",
        "    self.add = layers.Add()\n",
        "    self.relu2 = layers.Activation('relu')\n",
        "    \n",
        "  @convert()\n",
        "  def call(self, inputs, skip=False):\n",
        "    \n",
        "    bypass = self.bypass1(inputs)\n",
        "    bypass = self.bypass2(bypass)\n",
        "    \n",
        "    #if skip:\n",
        "    #  return bypass\n",
        "    \n",
        "    result = self.conv1(inputs)\n",
        "    result = self.bn1(result)\n",
        "    result = self.relu1(result)\n",
        "    result = self.conv2(result)\n",
        "    result = self.bn2(result)\n",
        "    result = self.add([result, bypass])\n",
        "    result = self.relu2(result)\n",
        "  \n",
        "    return result    \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFgUFij5RfJB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_model(res_blocks_per_group, start_channels=16, groups=3):\n",
        "  channels = start_channels\n",
        "  \n",
        "  model = tf.keras.Sequential([\n",
        "      layers.Lambda(\n",
        "          lambda x: tf.image.convert_image_dtype(x, dtype=tf.float32)),\n",
        "      layers.Conv2D(channels,(3,3), padding='same',\n",
        "                    kernel_initializer='he_normal')\n",
        "  ])\n",
        "\n",
        "  stocastic = StocasticNetworkDepth(1.0, 0.5)\n",
        "  \n",
        "  for group in range(groups):\n",
        "    for block in range(res_blocks_per_group):\n",
        "      downsample = block == 0 and group != 0\n",
        "      stocastic.add(SkippableResBlock(channels, downsample=downsample))        \n",
        "    channels *= 2\n",
        "  \n",
        "  stocastic.build([None, None, None, start_channels])\n",
        "  model.add(stocastic)\n",
        "  model.add(layers.GlobalAvgPool2D())\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t0d0mVWpKD2T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 1\n",
        "\n",
        "train, test = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "train_data, train_labels = train\n",
        "\n",
        "test_data, test_labels = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ZYyzc2ctEB-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = make_model(18)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3zCFrQvQXB_F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YG7VmrCBULCe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "  base_lr = 0.1\n",
        "  \n",
        "  lr = base_lr\n",
        "  if epoch>250:\n",
        "    lr /= 10\n",
        "    \n",
        "  if epoch>375:\n",
        "    lr /= 10\n",
        "    \n",
        "  return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AAaa2oA1XJ1v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(schedule=lr_schedule)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lw9F7xpzl_gT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [cp_callback, lr_callback]\n",
        "optimizer = tf.keras.optimizers.SGD(decay=1e-4, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer, loss='sparse_categorical_crossentropy',\n",
        "              callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19e6KMMk7U6s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.build([None, None, None, 3])\n",
        "#model(tf.convert_to_tensor(test_data[:10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iKVQPSEdk1fM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.build(tf.TensorShape([None, None, None, 3]))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FIOPh__B8UQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.layers[2].summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uptkE_C8_isl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.layers[2].layers[-1].summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nzst0_CH2uXV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_data, train_labels, epochs=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bv5iBdlhkyN_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RdRP1uh3Z_vj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}